{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbde711",
   "metadata": {},
   "source": [
    "uses Pima Indians Diabetes Database\n",
    "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database\n",
    "\n",
    "Supervised learning\n",
    "Binary logistic regression + Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26cd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy, pandas, matplotlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1be706a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "df = pandas.read_csv(\"diabetes.csv\")\n",
    "df.head() #prints first 5 rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677b6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing to see trends per label\n",
    "# cols = df.columns.tolist()  \n",
    "# feature_cols = cols[:-1]    \n",
    "\n",
    "# for feature in feature_cols:\n",
    "#     matplotlib.pyplot.hist(\n",
    "#         df[df[\"Outcome\"] == 1][feature],\n",
    "#         color='blue',\n",
    "#         label='Diabetes (1)',\n",
    "#         alpha=0.7,\n",
    "#         density=True\n",
    "#     )\n",
    "#     matplotlib.pyplot.hist(\n",
    "#         df[df[\"Outcome\"] == 0][feature],\n",
    "#         color='red',\n",
    "#         label='No Diabetes (0)',\n",
    "#         alpha=0.7,\n",
    "#         density=True\n",
    "#     )\n",
    "#     matplotlib.pyplot.title(feature)\n",
    "#     matplotlib.pyplot.ylabel(\"Probability\")\n",
    "#     matplotlib.pyplot.xlabel(feature)\n",
    "#     matplotlib.pyplot.legend()\n",
    "#     matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d01c6b",
   "metadata": {},
   "source": [
    "DATA SEPARATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec3e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into x and y (pregnancies - age: x; outcome: y)\n",
    "y = df[\"Outcome\"].values\n",
    "X = df.drop(columns=[\"Outcome\"]).values\n",
    "\n",
    "# separate data to get training, valid and test set\n",
    "# 70% train, 20% valid, remain=10% test\n",
    "X_temp, x_test, y_temp, y_test = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)\n",
    "X_train, x_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.2222, stratify=y_temp, random_state=42)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "x_train = scaler.transform(X_train)\n",
    "x_valid = scaler.transform(x_valid)\n",
    "x_test  = scaler.transform(x_test )\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train, y_train = ros.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba5552",
   "metadata": {},
   "source": [
    "TRAIN LOGISTIC REGRESSION MODEL AND PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d43f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7386\n",
      "Train Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       350\n",
      "           1       0.75      0.71      0.73       350\n",
      "\n",
      "    accuracy                           0.74       700\n",
      "   macro avg       0.74      0.74      0.74       700\n",
      "weighted avg       0.74      0.74      0.74       700\n",
      "\n",
      "Validation Accuracy: 0.7922\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       100\n",
      "           1       0.67      0.81      0.73        54\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.78      0.80      0.78       154\n",
      "weighted avg       0.81      0.79      0.80       154\n",
      "\n",
      "Test Accuracy: 0.7792\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81        50\n",
      "           1       0.64      0.85      0.73        27\n",
      "\n",
      "    accuracy                           0.78        77\n",
      "   macro avg       0.77      0.80      0.77        77\n",
      "weighted avg       0.81      0.78      0.78        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "log_reg_model = LogisticRegression(max_iter=100, random_state=42)\n",
    "log_reg_model.fit(x_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_train_pred = log_reg_model.predict(x_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train Accuracy:\", round(train_acc, 4))\n",
    "print(\"Train Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Validation dataset \n",
    "y_valid_pred = log_reg_model.predict(x_valid)\n",
    "valid_acc = accuracy_score(y_valid, y_valid_pred)\n",
    "print(\"Validation Accuracy:\", round(valid_acc, 4))\n",
    "print(\"Validation Classification Report:\\n\", classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "# Test dataset \n",
    "y_test_pred = log_reg_model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", round(test_acc, 4))\n",
    "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f413eb",
   "metadata": {},
   "source": [
    "Building a Neural Net using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1cbfcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize loss and accuracy\n",
    "def plot_loss(history):\n",
    "    matplotlib.pyplot.plot(history.history['loss'], label='loss')\n",
    "    matplotlib.pyplot.plot(history.history['val_loss'], label='val_loss')\n",
    "    matplotlib.pyplot.xlabel('Epoch')\n",
    "    matplotlib.pyplot.ylabel('Binary Crossentropy')\n",
    "    matplotlib.pyplot.legend()\n",
    "    matplotlib.pyplot.grid(True)\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "def plot_accuracy(history):\n",
    "    matplotlib.pyplot.plot(history.history['accuracy'], label='accuracy')\n",
    "    matplotlib.pyplot.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    matplotlib.pyplot.xlabel('Epoch')\n",
    "    matplotlib.pyplot.ylabel('Accuracy')\n",
    "    matplotlib.pyplot.legend()\n",
    "    matplotlib.pyplot.grid(True)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b5d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x_train.shape[1]\n",
    "# num_nodes = 17 #2n+1 n=num of features\n",
    "\n",
    "# build a function which can be called to train different FNN models with different arguments so that the best can be found\n",
    "def train_model(x_train, y_train, num_nodes, dropout_prob, learning_rate, batch_size, epochs):\n",
    "    fnn_model = tensorflow.keras.Sequential([\n",
    "            tensorflow.keras.layers.Input(shape=(features,)),  # hyperparameters, tuple\n",
    "            tensorflow.keras.layers.Dropout(dropout_prob),\n",
    "            tensorflow.keras.layers.Dense(num_nodes, activation='relu'),\n",
    "            tensorflow.keras.layers.Dense(num_nodes, activation='relu', ),\n",
    "            tensorflow.keras.layers.Dense(1, activation='sigmoid') # can easily round this to (0, or 1)\n",
    "        ])\n",
    "\n",
    "    fnn_model.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate), \n",
    "                      loss='binary_crossentropy',\n",
    "                    metrics=['accuracy']) #Optimizers will adjust the weight of the model based on loss function hence +accuracy\n",
    "\n",
    "    history = fnn_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid), verbose=0)\n",
    "\n",
    "    return fnn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a98e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 nodes, 0.0 dropout, 0.005 learning rate, 64 batch size\n",
      " validation loss is 1.0405486822128296, validation accuracy is 0.6948052048683167\n",
      "17 nodes, 0.0 dropout, 0.005 learning rate, 128 batch size\n",
      " validation loss is 0.795328676700592, validation accuracy is 0.7467532753944397\n",
      "17 nodes, 0.0 dropout, 0.001 learning rate, 64 batch size\n"
     ]
    }
   ],
   "source": [
    "# grid to find best model out of many trained models\n",
    "\n",
    "least_val_loss = float('inf')\n",
    "least_loss_model = None\n",
    "epochs = 100\n",
    "\n",
    "for num_nodes in [17, 64]:\n",
    "    for dropout_prob in [0.0, 0.2]:\n",
    "        for learning_rate in [0.005, 0.001, 0.01]:\n",
    "            for batch_size in [64, 128]:\n",
    "                print(f\"{num_nodes} nodes, {dropout_prob} dropout, {learning_rate} learning rate, {batch_size} batch size\")\n",
    "                model, history = train_model(\n",
    "                    x_train, y_train,\n",
    "                    num_nodes=num_nodes,\n",
    "                    dropout_prob=dropout_prob,\n",
    "                    learning_rate=learning_rate,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs\n",
    "                )\n",
    "\n",
    "                # plot_loss(history)\n",
    "                # plot_accuracy(history)\n",
    "\n",
    "                validation_loss, validation_acc = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "                print(f\" validation loss is {validation_loss}, validation accuracy is {validation_acc}\")\n",
    "\n",
    "                # keep best \n",
    "                if validation_loss < least_val_loss:\n",
    "                    least_val_loss = validation_loss\n",
    "                    least_loss_model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba32d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.59      0.71        54\n",
      "           1       0.46      0.83      0.59        23\n",
      "\n",
      "    accuracy                           0.66        77\n",
      "   macro avg       0.68      0.71      0.65        77\n",
      "weighted avg       0.76      0.66      0.68        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final test run with the best model\n",
    "y_prob = least_loss_model.predict(x_test, verbose=0).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int).reshape(-1,) # round to 0 or 1. threshold=0.5\n",
    "\n",
    "print(\"Final Model Classification Score\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d165c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
